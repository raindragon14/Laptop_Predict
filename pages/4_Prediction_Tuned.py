import streamlit as st
import pandas as pd
import joblib
import os
import numpy as np
import re
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import matplotlib.pyplot as plt
import seaborn as sns
import plotly.express as px
import plotly.graph_objects as go
from plotly.subplots import make_subplots

st.set_page_config(page_title="Laptop Price Prediction (Optimized Model)", page_icon="ğŸ’»", layout="wide")

st.title("ğŸ’» Laptop Price Prediction (Optimized Model)")
st.markdown("Please provide the laptop specifications below to obtain an accurate price estimation using our optimized ensemble model.")

# Model path for fine tuned model
MODEL_PATH = 'optimized_weighted_ensemble_laptop_price_model.joblib'
DATA_PATH = 'laptop_prices.csv'

def process_memory(memory_str):
    """Process memory string to extract storage type and size"""
    memory_str = str(memory_str).strip().lower()
    if '+' in memory_str:
        memory_str = memory_str.split('+')[0].strip()
    storage_type = 'Other'
    if 'ssd' in memory_str: storage_type = 'SSD'
    elif 'hdd' in memory_str: storage_type = 'HDD'
    elif 'flash' in memory_str: storage_type = 'Flash Storage'
    elif 'hybrid' in memory_str: storage_type = 'Hybrid'
    size_gb = 0
    num_match = re.search(r'(\d+\.?\d*)', memory_str)
    if num_match:
        size = float(num_match.group(1))
        size_gb = size * 1000 if 'tb' in memory_str else size
    return pd.Series([size_gb, storage_type])

def create_engineered_features(df):
    """
    Create additional features required by the optimized model
    Based on feature engineering methodology
    """
    df = df.copy()
    
    # 1. Screen Area
    df['ScreenArea'] = df['ScreenW'] * df['ScreenH'] / 1000000  # in million pixels
    
    # 2. Pixel Density
    df['PixelDensity'] = np.sqrt(df['ScreenW']**2 + df['ScreenH']**2) / df['Inches']
    
    # 3. RAM per inch (RAM efficiency based on screen size)
    df['RAM_per_inch'] = df['Ram'] / df['Inches']
    
    # 4. Storage per RAM ratio
    df['Storage_per_RAM'] = df['PrimaryStorage'] / np.maximum(df['Ram'], 1)
    
    # 5. Size Weight ratio (portability)
    df['Size_Weight_ratio'] = df['Inches'] / np.maximum(df['Weight'], 0.1)
    
    # 6. RAM CPU interaction
    df['RAM_CPU_interaction'] = df['Ram'] * df['CPU_freq']
    
    # 7. Premium Brand Indicator
    premium_brands = ['Apple', 'Dell', 'HP', 'Lenovo', 'Asus', 'Microsoft', 'Razer']
    df['Is_Premium_Brand'] = df['Company'].apply(lambda x: 1 if x in premium_brands else 0)
    
    # 8. Performance Score (combined performance factors)
    # Feature normalization for scoring
    ram_norm = np.log1p(df['Ram']) / np.log1p(64)  # Max RAM 64GB
    cpu_norm = df['CPU_freq'] / 4.0  # Max CPU freq 4GHz
    storage_norm = np.log1p(df['PrimaryStorage']) / np.log1p(2048)  # Max storage 2TB
    
    # Weighted performance score
    df['Performance_Score'] = (
        ram_norm * 0.4 +           # RAM 40%
        cpu_norm * 0.35 +          # CPU 35%
        storage_norm * 0.15 +      # Storage 15%
        df['PixelDensity'] / 500 * 0.1  # Display quality 10%
    )
    
    # 9. Portability Score
    df['Portability_Score'] = (
        (5.0 - df['Weight']) / 4.0 * 0.6 +  # Weight factor (lighter is better)
        (20.0 - df['Inches']) / 10.0 * 0.4   # Size factor (smaller is better)
    )
    # Clamp to 0-1 range
    df['Portability_Score'] = np.clip(df['Portability_Score'], 0, 1)
    
    return df

@st.cache_resource
def load_model():
    """Load the optimized ensemble model"""
    if not os.path.exists(MODEL_PATH):
        st.error(f"Model file '{MODEL_PATH}' not found. Please ensure the model has been trained.")
        return None
    try:
        model = joblib.load(MODEL_PATH)
        st.success("âœ… Optimized model loaded successfully!")
        return model
    except Exception as e:
        st.error(f"Failed to load model: {e}")
        return None

@st.cache_data
def get_data_options():
    """Load data to obtain input options"""
    if not os.path.exists(DATA_PATH):
        st.error(f"Data file '{DATA_PATH}' not found.")
        return None
    try:
        df = pd.read_csv(DATA_PATH, encoding='latin-1')
        
        # Consistent preprocessing with other pages
        if 'Ram' in df.columns and df['Ram'].dtype == 'object':
            df['Ram'] = df['Ram'].str.replace('GB', '', regex=False).astype('int32')
        
        if 'Weight' in df.columns and df['Weight'].dtype == 'object':
            df['Weight'] = df['Weight'].str.replace('kg', '', regex=False).astype('float32')

        return df
    except Exception as e:
        st.error(f"Failed to process data for input options: {e}")
        return None

@st.cache_data
def get_model_performance_metrics():
    return {
        'weighted_ensemble': {
            'name': 'Weighted Ensemble (Best)',
            'r2': 0.8694,
            'mae': 2.6766,
            'rmse': 3.67,
            'mape': 15.8,
            'rank': 1
        },
        'voting_ensemble': {
            'name': 'Voting Ensemble',
            'r2': 0.8694,
            'mae': 2.6765,
            'rmse': 3.67,
            'mape': 15.8,
            'rank': 2
        },
        'xgboost': {
            'name': 'XGBoost',
            'r2': 0.8630,
            'mae': 2.8458,
            'rmse': 3.84,
            'mape': 16.9,
            'rank': 3
        },
        'gradient_boosting': {
            'name': 'Gradient Boosting',
            'r2': 0.8610,
            'mae': 2.9091,
            'rmse': 3.95,
            'mape': 17.3,
            'rank': 4
        },
        'extra_trees': {
            'name': 'Extra Trees',
            'r2': 0.8527,
            'mae': 2.9653,
            'rmse': 4.05,
            'mape': 17.8,
            'rank': 5
        },
        'random_forest': {
            'name': 'Random Forest',
            'r2': 0.8497,
            'mae': 2.8770,
            'rmse': 3.93,
            'mape': 17.1,
            'rank': 6
        },
        'lightgbm': {
            'name': 'LightGBM',
            'r2': 0.8466,
            'mae': 2.8579,
            'rmse': 3.91,
            'mape': 17.0,
            'rank': 7
        }
    }

@st.cache_data
def load_model_performance():
    """Load model performance metrics"""
    try:
        # Try to load metrics from file if available
        metrics_path = 'model_performance_metrics.joblib'
        if os.path.exists(metrics_path):
            metrics = joblib.load(metrics_path)
            return metrics
        else:
            performance_metrics = get_model_performance_metrics()
            # Return weighted ensemble (best model) as default
            best_metrics = performance_metrics['weighted_ensemble']
            return {
                'r2': best_metrics['r2'],
                'mae': best_metrics['mae'],
                'rmse': best_metrics['rmse'],
                'mape': best_metrics['mape'],
                'n_samples': 255,  # 20% of 1275 data points
                'model_name': best_metrics['name'],
                'rank': best_metrics['rank']
            }
    except Exception as e:
        st.warning(f"Unable to load model performance data: {e}")
        return None

def display_model_comparison():
    st.header("ğŸ“Š Model Performance Comparison")
    
    performance_metrics = get_model_performance_metrics()
    
    # Create comparison DataFrame
    comparison_data = []
    for model_key, metrics in performance_metrics.items():
        comparison_data.append({
            'Model': metrics['name'],
            'Rank': metrics['rank'],
            'RÂ² Score': metrics['r2'],
            'MAE (Million IDR)': metrics['mae'],
            'RMSE (Million IDR)': metrics['rmse'],
            'MAPE (%)': metrics['mape']
        })
    
    df_comparison = pd.DataFrame(comparison_data).sort_values('Rank')
    
    # Display as table with ranking
    st.subheader("ğŸ† Model Performance Ranking")
    
    # Style the dataframe
    def highlight_best(s):
        if s.name == 'RÂ² Score':
            return ['background-color: gold' if v == s.max() else '' for v in s]
        elif s.name == 'MAE (Million IDR)':
            return ['background-color: lightgreen' if v == s.min() else '' for v in s]
        else:
            return ['' for _ in s]
    
    styled_df = df_comparison.style.apply(highlight_best, axis=0)
    st.dataframe(styled_df, use_container_width=True)
    
    # Create visualizations
    col1, col2 = st.columns(2)
    
    with col1:
        # RÂ² Score comparison
        fig_r2 = px.bar(
            df_comparison, 
            x='Model', 
            y='RÂ² Score',
            title='ğŸ“Š RÂ² Score Comparison',
            color='RÂ² Score',
            color_continuous_scale='Viridis',
            text='RÂ² Score'
        )
        fig_r2.update_traces(texttemplate='%{text:.4f}', textposition='outside')
        fig_r2.update_layout(xaxis_tickangle=-45, height=500)
        st.plotly_chart(fig_r2, use_container_width=True)
    
    with col2:
        # MAE comparison
        fig_mae = px.bar(
            df_comparison, 
            x='Model', 
            y='MAE (Million IDR)',
            title='ğŸ“‰ MAE Comparison - Lower is Better',
            color='MAE (Million IDR)',
            color_continuous_scale='Reds_r',
            text='MAE (Million IDR)'
        )
        fig_mae.update_traces(texttemplate='%{text:.3f}', textposition='outside')
        fig_mae.update_layout(xaxis_tickangle=-45, height=500)
        st.plotly_chart(fig_mae, use_container_width=True)
    
    # Highlight best models
    best_model = df_comparison.iloc[0]  # First row after sorting by rank
    st.success(f"ğŸ† **Best Model:** {best_model['Model']} with RÂ² Score: {best_model['RÂ² Score']:.4f} and MAE: {best_model['MAE (Million IDR)']:.4f} Million IDR")
    
    # Performance insights
    st.subheader("ğŸ” Performance Insights")
    col1, col2, col3 = st.columns(3)
    
    with col1:
        st.metric(
            "ğŸ¥‡ Best RÂ² Score", 
            f"{df_comparison['RÂ² Score'].max():.4f}",
            help="Weighted Ensemble achieved the highest accuracy"
        )
    
    with col2:
        st.metric(
            "ğŸ¯ Lowest MAE", 
            f"{df_comparison['MAE (Million IDR)'].min():.4f} Million",
            help="Lowest average error"
        )
    
    with col3:
        performance_gap = df_comparison['RÂ² Score'].max() - df_comparison['RÂ² Score'].min()
        st.metric(
            "ğŸ“Š Performance Gap", 
            f"{performance_gap:.4f}",
            help="Performance difference between best and worst models"
        )

def display_model_performance():
    """Display model performance metrics with comprehensive analysis"""
    st.header("ğŸ¯ Optimized Model Performance")
    
    metrics = load_model_performance()
    
    if metrics is None:
        st.info("ğŸ“ˆ Optimized model is ready for use! Performance metrics will be displayed when evaluation data becomes available.")
        return
    
    # Performance summary banner
    st.success(f"ğŸ† {metrics.get('model_name', 'Weighted Ensemble')} - Rank #{metrics.get('rank', 1)} - Top performing model from comprehensive evaluation")
    
    # Display metrics in columns
    col1, col2, col3, col4 = st.columns(4)
    
    with col1:
        st.metric(
            label="ğŸ¯ RÂ² Score",
            value=f"{metrics['r2']:.4f}",
            help="Coefficient of determination - closer to 1 indicates better performance",
            delta=f"Rank #{metrics.get('rank', 1)} of 7 models"
        )
    
    with col2:
        st.metric(
            label="ğŸ“Š MAE (Million IDR)",
            value=f"{metrics['mae']:.4f}",
            help="Mean Absolute Error - average absolute prediction error",
            delta="Lowest error!" if metrics.get('rank', 1) == 1 else None
        )
    
    with col3:
        st.metric(
            label="ğŸ“ˆ RMSE (Million IDR)",
            value=f"{metrics['rmse']:.2f}",
            help="Root Mean Square Error - square root of average squared errors"
        )
    
    with col4:
        st.metric(
            label="ğŸ“‹ MAPE (%)",
            value=f"{metrics['mape']:.1f}%",
            help="Mean Absolute Percentage Error - average percentage error"
        )
    
    # Performance interpretation
    st.subheader("ğŸ¯ Model Performance Interpretation")
    
    if metrics['r2'] >= 0.85:
        performance_level = "Excellent"
        performance_icon = "ğŸŒŸ"
    elif metrics['r2'] >= 0.80:
        performance_level = "Good"
        performance_icon = "âœ…"
    elif metrics['r2'] >= 0.75:
        performance_level = "Satisfactory"
        performance_icon = "âš¡"
    else:
        performance_level = "Needs Improvement"
        performance_icon = "âš ï¸"
    
    avg_error_rupiah = metrics['mae'] * 1000000  # Convert to rupiah
    
    # Use native Streamlit components for layout
    st.info(f"{performance_icon} **Performance Level: {performance_level}**")
    
    col1, col2 = st.columns(2)
    
    with col1:
        st.write("**ğŸ“Š Accuracy & Precision:**")
        st.write(f"â€¢ **ğŸ¯ RÂ² Score:** {metrics['r2']:.1%} - Model explains {metrics['r2']:.1%} of price variation")
        st.write(f"â€¢ **ğŸ“‹ Average Error:** IDR {avg_error_rupiah:,.0f}")
        st.write(f"â€¢ **ğŸ“ˆ Percentage Error:** Â±{metrics['mape']:.1f}% of actual price")
    
    with col2:
        st.write("**ğŸ” Data & Performance:**")
        st.write(f"â€¢ **ğŸ† Ranking:** #{metrics.get('rank', 1)} of 7 models")
        st.write(f"â€¢ **ğŸ“Š Evaluation Data:** {metrics['n_samples']} laptops")
        st.write(f"â€¢ **ğŸ¯ Model Type:** {metrics.get('model_name', 'Weighted Ensemble')}")
    
    # Conclusion
    st.success(f"""
    **ğŸ’¡ Practical Interpretation:**
    
    âœ… **High Accuracy:** Model predicts with {metrics['r2']:.1%} accuracy
    
    ğŸ’° **Low Error:** Predictions deviate on average by only Â±{metrics['mape']:.1f}%
    
    ğŸš€ **Optimal:** Selected as the best model from 7 tested algorithms
    
    ğŸ¯ **Conclusion:** Model is highly suitable for laptop price estimation with high confidence level
    """)

def display_feature_importance():
    """Display feature importance analysis"""
    st.subheader("ğŸ“Š Feature Importance Analysis")
    
    # Updated feature importance based on ensemble results
    feature_importance = {
        'Performance_Score': 0.22,
        'CPU_freq': 0.16,
        'Ram': 0.14,
        'RAM_CPU_interaction': 0.11,
        'PrimaryStorage': 0.09,
        'Is_Premium_Brand': 0.08,
        'PixelDensity': 0.06,
        'ScreenArea': 0.05,
        'Portability_Score': 0.04,
        'Storage_per_RAM': 0.03,
        'RAM_per_inch': 0.02
    }
    
    # Create DataFrame
    df_importance = pd.DataFrame([
        {'Feature': feature, 'Importance': importance}
        for feature, importance in feature_importance.items()
    ]).sort_values('Importance', ascending=True)
    
    # Create horizontal bar chart
    fig = px.bar(
        df_importance,
        x='Importance',
        y='Feature',
        orientation='h',
        title='ğŸ¯ Feature Contribution to Price Prediction (Weighted Ensemble)',
        labels={'Importance': 'Importance Level', 'Feature': 'Features'},
        color='Importance',
        color_continuous_scale='RdYlBu_r',
        text='Importance'
    )
    fig.update_traces(texttemplate='%{text:.3f}', textposition='inside')
    fig.update_layout(height=500)
    st.plotly_chart(fig, use_container_width=True)
    
    # Explanation
    st.info("""
    ğŸ’¡ **Feature Interpretation (Weighted Ensemble Model):**
    - **Performance_Score (22%)**: Combined performance metric is the most important factor
    - **CPU_freq (16%)**: CPU frequency remains highly influential on price
    - **Ram (14%)**: RAM capacity continues to be a primary factor
    - **RAM_CPU_interaction (11%)**: Synergy between RAM and CPU affects pricing
    - **Brand Premium (8%)**: Premium brand status contributes significantly
    - **Storage & Display**: Storage and display features have moderate influence
    """)

# Load model and data
model = load_model()
df_options = get_data_options()

# Display model performance at the top
if model is not None:
    display_model_performance()
    st.divider()
    
    # Display model comparison
    with st.expander("ğŸ“Š View All Model Comparisons", expanded=False):
        display_model_comparison()
    
    # Display feature importance
    with st.expander("ğŸ¯ Feature Importance Analysis", expanded=False):
        display_feature_importance()
    
    st.divider()

if model and df_options is not None:
    with st.form("prediction_form"):
        st.header("ğŸ”§ Core Specifications")
        col1, col2, col3 = st.columns(3)
        
        with col1:
            company = st.selectbox("Brand", options=sorted(df_options['Company'].unique()))
            type_name = st.selectbox("Laptop Type", options=sorted(df_options['TypeName'].unique()))
            ram = st.selectbox("RAM (GB)", options=sorted(df_options['Ram'].unique()))
            
        with col2:
            opsys = st.selectbox("Operating System", options=sorted(df_options['OS'].unique()))
            weight = st.slider("Weight (kg)", min_value=0.5, max_value=5.0, value=1.5, step=0.1)
            inches = st.slider("Screen Size (Inches)", min_value=10.0, max_value=18.0, value=15.6, step=0.1)
            
        with col3:
            cpu_company = st.selectbox("CPU Brand", options=sorted(df_options['CPU_company'].unique()))
            gpu_company = st.selectbox("GPU Brand", options=sorted(df_options['GPU_company'].unique()))
            cpu_freq = st.slider("CPU Frequency (GHz)", min_value=0.9, max_value=4.0, value=2.5, step=0.1)

        st.header("ğŸ’¾ Storage & Display")
        col4, col5, col6 = st.columns(3)
        
        with col4:
            storage_type = st.selectbox("Primary Storage Type", options=sorted(df_options['PrimaryStorageType'].unique()))
            primary_storage = st.select_slider("Storage Capacity (GB)", 
                                             options=sorted(df_options[df_options['PrimaryStorage'] > 0]['PrimaryStorage'].unique()), 
                                             value=256)
            
        with col5:
            if 'ScreenResolution' in df_options.columns:
                screen_resolution = st.selectbox("Screen Resolution", options=sorted(df_options['ScreenResolution'].unique()))
                res_match = re.search(r'(\d+)x(\d+)', screen_resolution)
                screen_w = int(res_match.group(1)) if res_match else 1920
                screen_h = int(res_match.group(2)) if res_match else 1080
            else:
                screen_w = st.number_input("Screen Width (px)", value=1920, min_value=800, max_value=4000, step=1)
                screen_h = st.number_input("Screen Height (px)", value=1080, min_value=600, max_value=3000, step=1)
                
        with col6:
            touchscreen_str = st.radio("Touchscreen", options=['No', 'Yes'], horizontal=True)
            ips_str = st.radio("IPS Panel", options=['No', 'Yes'], horizontal=True)
            touchscreen = 1 if touchscreen_str == 'Yes' else 0
            ips = 1 if ips_str == 'Yes' else 0

        submit_button = st.form_submit_button(label="ğŸš€ Predict Price (Weighted Ensemble)", type="primary", use_container_width=True)

    if submit_button:
        # Prepare input data consistent with expected format
        input_data = pd.DataFrame({
            'Company': [company], 
            'TypeName': [type_name], 
            'Ram': [ram],
            'Weight': [weight], 
            'OS': [opsys], 
            'Inches': [inches],
            'CPU_company': [cpu_company], 
            'CPU_freq': [cpu_freq],
            'GPU_company': [gpu_company], 
            'PrimaryStorage': [primary_storage],
            'PrimaryStorageType': [storage_type], 
            'ScreenW': [screen_w],
            'ScreenH': [screen_h], 
            'Touchscreen': [touchscreen], 
            'IPSpanel': [ips]
        })

        # âœ¨ IMPORTANT: Add engineered features expected by the model
        input_data_engineered = create_engineered_features(input_data)

        st.info("ğŸ“‹ Your Input Data:")
        st.dataframe(input_data, use_container_width=True)
        
        # Show engineered features
        with st.expander("ğŸ”§ Calculated Additional Features"):
            engineered_features = input_data_engineered[['ScreenArea', 'PixelDensity', 'RAM_per_inch', 
                                                       'Storage_per_RAM', 'Size_Weight_ratio', 'RAM_CPU_interaction',
                                                       'Is_Premium_Brand', 'Performance_Score', 'Portability_Score']].round(4)
            st.dataframe(engineered_features, use_container_width=True)

        with st.spinner("ğŸ† Weighted Ensemble model analyzing specifications..."):
            try:
                # Prediction with optimized model using complete feature set
                prediction = model.predict(input_data_engineered)
                
                # Handle different prediction formats
                if isinstance(prediction, np.ndarray):
                    predicted_price = float(prediction[0])
                else:
                    predicted_price = float(prediction)
                
                # If model uses log transform, convert back
                try:
                    predicted_price_exp = np.expm1(predicted_price)
                    # Check if exp result is reasonable
                    if predicted_price_exp > 0 and predicted_price_exp < predicted_price * 100:
                        predicted_price = predicted_price_exp
                except:
                    pass
                
                # Display prediction with confidence interval
                metrics = load_model_performance()
                if metrics and metrics['mae'] > 0:
                    confidence_interval = metrics['mae'] * 1.96  # 95% confidence interval
                    lower_bound = max(0, predicted_price - confidence_interval)
                    upper_bound = predicted_price + confidence_interval
                    
                    col1, col2 = st.columns([2, 1])
                    
                    with col1:
                        st.success(f"## ğŸ† **Price Estimation (Weighted Ensemble): IDR {predicted_price:,.2f} Million**")
                        st.info(f"ğŸ“Š **95% Confidence Interval:** IDR {lower_bound:,.2f} - {upper_bound:,.2f} Million")
                        st.caption(f"*ğŸ¯ Prediction using {metrics.get('model_name', 'Weighted Ensemble')} - Rank #{metrics.get('rank', 1)} with {metrics['r2']:.1%} accuracy and Â±{metrics['mape']:.1f}% average error*")
                    
                    with col2:
                        # Price category
                        if predicted_price < 10:
                            category = "ğŸ’° Budget"
                            cat_color = "#4CAF50"
                        elif predicted_price < 25:
                            category = "ğŸ”¥ Mid-Range"
                            cat_color = "#FF9800"
                        elif predicted_price < 50:
                            category = "â­ Premium"
                            cat_color = "#2196F3"
                        else:
                            category = "ğŸ‘‘ High-End"
                            cat_color = "#9C27B0"
                        
                        st.markdown(f"""
                        <div style="padding: 1.5rem; border: 3px solid {cat_color}; border-radius: 12px; text-align: center; background: linear-gradient(135deg, rgba(255,255,255,0.9), rgba(0,0,0,0.02));">
                            <h3 style="color: {cat_color}; margin: 0;">{category}</h3>
                            <p style="margin: 0.5rem 0 0 0; font-size: 0.9em; color: #666;">Laptop Category</p>
                        </div>
                        """, unsafe_allow_html=True)
                        
                else:
                    st.success(f"## ğŸ† **Price Estimation (Weighted Ensemble): IDR {predicted_price:,.2f} Million**")
                    st.caption("*ğŸ¯ Prediction using top-performing model from comprehensive evaluation*")
                
                # Additional insights
                with st.expander("ğŸ’¡ Insights & Comprehensive Specification Analysis"):
                    col1, col2 = st.columns(2)
                    
                    with col1:
                        st.markdown(f"""
                        **ğŸ”§ Specification Analysis:**
                        - **Category:** {type_name}
                        - **Brand:** {company} {"(Premium)" if company in ['Apple', 'Dell', 'HP', 'Lenovo'] else ""}
                        - **Performance:** RAM {ram}GB + CPU {cpu_freq}GHz + GPU {gpu_company}
                        - **Storage:** {primary_storage}GB {storage_type}
                        - **Display:** {screen_w}x{screen_h}{"" if touchscreen == 0 else " (Touchscreen)"}{"" if ips == 0 else " (IPS)"}
                        - **Weight:** {weight}kg
                        """)
                    
                    with col2:
                        performance_score = input_data_engineered['Performance_Score'].iloc[0]
                        portability_score = input_data_engineered['Portability_Score'].iloc[0]
                        pixel_density = input_data_engineered['PixelDensity'].iloc[0]
                        
                        # Performance level indicators
                        perf_level = "High" if performance_score > 0.7 else "Medium" if performance_score > 0.4 else "Low"
                        port_level = "Highly Portable" if portability_score > 0.7 else "Portable" if portability_score > 0.4 else "Less Portable"
                        
                        st.markdown(f"""
                        **ğŸ“Š Advanced Analysis Scores:**
                        - **Performance Score:** {performance_score:.3f}/1.000 ({perf_level})
                        - **Portability Score:** {portability_score:.3f}/1.000 ({port_level})
                        - **Pixel Density:** {pixel_density:.0f} PPI
                        - **Premium Brand:** {"âœ… Yes" if input_data_engineered['Is_Premium_Brand'].iloc[0] else "âŒ No"}
                        - **RAM-CPU Synergy:** {input_data_engineered['RAM_CPU_interaction'].iloc[0]:.1f}
                        - **Storage Efficiency:** {input_data_engineered['Storage_per_RAM'].iloc[0]:.1f}x
                        """)
                    
                    st.markdown(f"""
                    <div style="background: linear-gradient(90deg, #4CAF50, #45a049); color: white; padding: 1rem; border-radius: 8px; margin-top: 1rem;">
                        <strong>ğŸš€ Prediction Summary:</strong><br>
                        The Weighted Ensemble model (Rank #1 of 7 models) provides reliable prediction with {metrics['r2']:.1%} accuracy. 
                        This laptop configuration is estimated at <strong>IDR {predicted_price:,.0f} million</strong> with an error margin of Â±{metrics['mape']:.1f}%.
                    </div>
                    """, unsafe_allow_html=True)
                    
            except Exception as e:
                st.error(f"âŒ An error occurred during prediction: {e}")
                st.info("ğŸ”§ Please ensure the optimized model has been properly trained or try using the standard Prediction page.")
                
                # Debug info
                with st.expander("ğŸ” Debug Information"):
                    st.write("**Available columns in input data:**")
                    st.write(list(input_data_engineered.columns))
                    st.write("**Input data shape:**", input_data_engineered.shape)

else:
    if model is None:
        st.warning("âš ï¸ Optimized model is not available. Please ensure the model file exists or train the model first.")
    if df_options is None:
        st.warning("âš ï¸ Data is not available. Please ensure the data file exists.")
    
    st.info("""
    ğŸ’¡ **Requirements:** To use this page, please ensure you have:
    - Optimized model: `optimized_weighted_ensemble_laptop_price_model.joblib`
    - Dataset: `laptop_prices.csv` 
    
    ğŸ† **Weighted Ensemble Model** - Best performing model from comprehensive evaluation:
    - **ğŸ¯ Accuracy:** RÂ² = 0.8694 (86.94%)
    - **ğŸ“Š Error:** MAE = 2.6766 Million IDR
    - **ğŸ† Ranking:** #1 of 7 tested algorithms
    - **ğŸ”§ Features:** 25+ features including engineered features
    - **âš¡ Technology:** Ensemble of Random Forest, XGBoost, Gradient Boosting, etc.
    """)
